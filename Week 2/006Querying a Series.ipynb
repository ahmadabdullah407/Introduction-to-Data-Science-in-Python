{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, we'll talk about one of the primary data types of the Pandas library, the Series. You'll learn about the structure of the Series, how to query and merge Series objects together, and the importance of thinking about parallelization when engaging in data science programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying a Series\n",
    "## get data out of a series:\n",
    "A pandas Series can be queried either by the index position or the index label. If you don't give an \n",
    "index to the series when querying, the position and the label are effectively the same values. To \n",
    "query by numeric location, starting at zero, use the iloc attribute. To query by the index label, \n",
    "you can use the loc attribute. \n",
    "Lets start with an example. We'll use students enrolled in classes coming from a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alice      Physics\n",
       "Jack     Chemistry\n",
       "Molly      English\n",
       "Sam        History\n",
       "dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "students_classes = {'Alice': 'Physics',\n",
    "                   'Jack': 'Chemistry',\n",
    "                   'Molly': 'English',\n",
    "                   'Sam': 'History'}\n",
    "s = pd.Series(students_classes)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iloc attribute:\n",
    "So, for this series, if you wanted to see the fourth entry we would we would use the iloc \n",
    "attribute with the parameter 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'History'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loc attribute:\n",
    "If you wanted to see what class Molly has, we would use the loc attribute with a parameter \n",
    "of Molly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.loc['Molly']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "Keep in mind that iloc and loc are not methods, they are attributes. So you don't use \n",
    "parentheses to query them, but square brackets instead, which is called the indexing operator. \n",
    "In Python this calls get or set for an item depending on the context of its use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might seem a bit confusing if you're used to languages where encapsulation of attributes, \n",
    "variables, and properties is common, such as in Java."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smart syntax of panda for iloc and loc:\n",
    "Pandas tries to make our code a bit more readable and provides a sort of smart syntax using \n",
    "the indexing operator directly on the series itself. For instance, if you pass in an integer parameter, \n",
    "the operator will behave as if you want it to query via the iloc attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'History'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you pass in an object, it will query as if you wanted to use the label based loc attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s['Molly']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using numbers as index:\n",
    "So what happens if your index is a list of integers? This is a bit complicated and Pandas can't \n",
    "determine automatically whether you're intending to query by index position or index label. So \n",
    "you need to be careful when using the indexing operator on the Series itself. The safer option \n",
    "is to be more explicit and use the iloc or loc attributes directly.\n",
    "\n",
    "Here's an example using class and their classcode information, where classes are indexed by \n",
    "classcodes, in the form of integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_code = {99: 'Physics',\n",
    "              1000: 'Chemistry',\n",
    "              101: 'English',\n",
    "              102: 'History'}\n",
    "s = pd.Series(class_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try and call s[0] we get a key error because there's no item in the classes list with \n",
    "an index of zero, instead we have to call iloc explicitly if we want the first item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\.conda\\envs\\mypy3env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-c9c96910e542>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\mypy3env\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 882\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\mypy3env\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 989\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    990\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\mypy3env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "s[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, that didn't call s.iloc[0] underneath as one might expect, instead it \n",
    "generates an error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Physics'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "although loc is working but better to be safe than sorry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with a data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know how to get data out of the series, let's talk about working with the data. A common \n",
    "task is to want to consider all of the values inside of a series and do some sort of \n",
    "operation. This could be trying to find a certain number, or summarizing data or transforming \n",
    "the data in some way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iteration Approach:\n",
    "A typical programmatic approach to this would be to iterate over all the items in the series, \n",
    "and invoke the operation one is interested in. For instance, we could create a Series of \n",
    "integers representing student grades, and just try and get an average grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.0\n"
     ]
    }
   ],
   "source": [
    "grades = pd.Series([90, 80, 70, 60])\n",
    "total = 0\n",
    "for grade in grades:\n",
    "    total+=grade\n",
    "print(total/len(grades))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works, but it's slow. Modern computers can do many tasks simultaneously, especially, \n",
    "but not only, tasks involving mathematics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization Approach:\n",
    "Pandas and the underlying numpy libraries support a method of computation called vectorization. \n",
    "Vectorization works with most of the functions in the numpy library, including the sum function.\n",
    "\n",
    "Here's how we would really write the code using the numpy sum method. First we need to import \n",
    "the numpy module, \n",
    "Then we just call np.sum and pass in an iterable item. In this case, our panda series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "total = np.sum(grades)\n",
    "print(total/len(grades))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking which approach is faster:\n",
    "Now both of these methods create the same value, but is one actually faster? The Jupyter \n",
    "Notebook has a magic function which can help. \n",
    "\n",
    "First, let's create a big series of random numbers. This is used a lot when demonstrating \n",
    "techniques with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = pd.Series(np.random.randint(0,1000,10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### head() function:\n",
    "Now lets look at the top five items in that series to make sure they actually seem random. We\n",
    "can do this with the head() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    347\n",
       "1    777\n",
       "2    829\n",
       "3    208\n",
       "4    960\n",
       "dtype: int32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually verify that length of the series is correct using the len function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Magic Functions:\n",
    "Ok, we're confident now that we have a big series. The ipython interpreter has something called\n",
    "magic functions begin with a percentage sign. If we type this sign and then hit the Tab key, you\n",
    "can see a list of the available magic functions. You could write your own magic functions too, \n",
    "but that's a little bit outside of the scope of this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "% # hit tab key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cellular magic functions:\n",
    "Here, we're actually going to use what's called a cellular magic function. These start with two \n",
    "percentage signs and wrap the code in the current Jupyter cell.\n",
    "#### timit:\n",
    "The function we're going to use is called timeit. This function will run our code a few times to determine, on average, how long it takes.\n",
    "\n",
    "Let's run timeit with our original iterative code. You can give timeit the number of loops that \n",
    "you would like to run. By default, it is 1,000 loops. I'll ask timeit here to use 100 runs. Note that in order to use a cellular magic function, it has to be the first line in the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.39 ms ± 176 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "total = 0\n",
    "for number in numbers:\n",
    "    total+=number\n",
    "\n",
    "total/len(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad. Timeit ran the code and it doesn't seem to take very long at all. Now let's try with \n",
    "vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 µs ± 30.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "total=np.sum(numbers)\n",
    "total/len(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion(Parallel computing features):\n",
    "Wow! This is a pretty shocking difference in the speed and demonstrates why one should be \n",
    "aware of parallel computing features and start thinking in functional programming terms.\n",
    "Put more simply, vectorization is the ability for a computer to execute multiple instructions\n",
    "at once, and with high performance chips, especially graphics cards, you can get dramatic\n",
    "speedups. Modern graphics cards can run thousands of instructions in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting(Modifying):\n",
    "A Related feature in pandas and nummy is called broadcasting. With broadcasting, you can \n",
    "apply an operation to every value in the series, changing the series. For instance, if we\n",
    "wanted to increase every random variable by 2, we could do so quickly using the += operator \n",
    "directly on the Series object. \n",
    "\n",
    "Let's look at the head of our series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    347\n",
       "1    777\n",
       "2    829\n",
       "3    208\n",
       "4    960\n",
       "dtype: int32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now lets just increase everything in the series by 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    349\n",
       "1    779\n",
       "2    831\n",
       "3    210\n",
       "4    962\n",
       "dtype: int32"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers+=2\n",
    "numbers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### proceduarl iterating approach:\n",
    "The procedural way of doing this would be to iterate through all of the items in the \n",
    "series and increase the values directly. Pandas does support iterating through a series \n",
    "much like a dictionary, allowing you to unpack values easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iteritems() function:\n",
    "We can use the iteritems() function which returns a label and value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    349\n",
       "1    779\n",
       "2    831\n",
       "3    210\n",
       "4    962\n",
       "dtype: int32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for label, value in numbers.iteritems():\n",
    "    s.loc[label]= value+2\n",
    "numbers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpeedComaprison\n",
    "So the result is the same\n",
    "Lets take a look at some speed comparisons. First, lets try ten loops using the iterative approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.8 ms ± 3.76 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "# we'll create a blank new series of items to deal with\n",
    "s = pd.Series(np.random.randint(0,1000,1000))\n",
    "# And we'll just rewrite our loop from above.\n",
    "for label, value in s.iteritems():\n",
    "    s.loc[label]= value+2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try that using the broadcasting methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616 µs ± 150 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "# We need to recreate a series\n",
    "s = pd.Series(np.random.randint(0,1000,1000))\n",
    "# And we just broadcast with +=\n",
    "s+=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing. Not only is it significantly faster, but it's more concise and even easier \n",
    "to read too. The typical mathematical operations you would expect are vectorized, and the \n",
    "nump documentation outlines what it takes to create vectorized functions of your own. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding data to Series:\n",
    "One last note on using the indexing operators to access series data. The .loc attribute lets \n",
    "you not only modify data in place, but also add new data as well. If the value you pass in as \n",
    "the index doesn't exist, then a new entry is added. And keep in mind, indices can have mixed types. \n",
    "While it's important to be aware of the typing going on underneath, Pandas will automatically \n",
    "change the underlying NumPy types as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example using a Series of a few numbers. We could add some new value, maybe a university course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            1\n",
       "1            2\n",
       "2            3\n",
       "History    101\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3])\n",
    "s.loc['History'] = 101\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([0, 1, 2, 'History'], dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that mixed types for data values or index labels are no problem for Pandas. Since \n",
    "\"History\" is not in the original list of indices, s.loc['History'] essentially creates a \n",
    "new element in the series, with the index named \"History\", and the value of 102"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple values for an index:\n",
    "Up until now I've shown only examples of a series where the index values were unique. I want \n",
    "to end this lecture by showing an example where index values are not unique, and this makes \n",
    "pandas Series a little different conceptually then, for instance, a relational database.\n",
    "\n",
    "Lets create a Series with students and the courses which they have taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alice      Physics\n",
       "Jack     Chemistry\n",
       "Molly      English\n",
       "Sam        History\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students_classes = pd.Series({'Alice': 'Physics',\n",
    "                   'Jack': 'Chemistry',\n",
    "                   'Molly': 'English',\n",
    "                   'Sam': 'History'})\n",
    "students_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create a Series just for some new student Kelly, which lists all of the courses\n",
    "she has taken. We'll set the index to Kelly, and the data to be the names of courses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kelly    Philosophy\n",
       "Kelly          Arts\n",
       "Kelly          Math\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kelly_classes = pd.Series(['Philosophy', 'Arts', 'Math'], index=['Kelly', 'Kelly', 'Kelly'])\n",
    "kelly_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .append() on series:\n",
    "Finally, we can append all of the data in this new Series to the first using the .append()\n",
    "function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alice       Physics\n",
       "Jack      Chemistry\n",
       "Molly       English\n",
       "Sam         History\n",
       "Kelly    Philosophy\n",
       "Kelly          Arts\n",
       "Kelly          Math\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_students_classes = students_classes.append(kelly_classes)\n",
    "\n",
    "# This creates a series which has our original people in it as well as all of Kelly's courses\n",
    "all_students_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of important considerations when using append. First, Pandas will take \n",
    "the series and try to infer the best data types to use. In this example, everything is a string, \n",
    "so there's no problems here. Second, the append method doesn't actually change the underlying Series\n",
    "objects, it instead returns a new series which is made up of the two appended together. This is\n",
    "a common pattern in pandas - by default returning a new object instead of modifying in place - and\n",
    "one you should come to expect. By printing the original series we can see that that series hasn't\n",
    "changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alice      Physics\n",
       "Jack     Chemistry\n",
       "Molly      English\n",
       "Sam        History\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we see that when we query the appended series for Kelly, we don't get a single value, \n",
    "but a series itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kelly    Philosophy\n",
       "Kelly          Arts\n",
       "Kelly          Math\n",
       "dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_students_classes.loc['Kelly']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, we focused on one of the primary data types of the Pandas library, the Series. You learned how to query the Series, with .loc and .iloc, that the Series is an indexed data structure, how to merge two Series objects together with append(), and the importance of vectorization.\n",
    "\n",
    "There are many more methods associated with the Series object that we haven't talked about. But with these basics down, we'll move on to talking about the Panda's two-dimensional data structure, the DataFrame. The DataFrame is very similar to the series object, but includes multiple columns of data, and is the structure that you'll spend the majority of your time working with when cleaning and aggregating data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
